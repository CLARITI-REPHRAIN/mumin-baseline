- size: small
  type: claim
  frozen: false
  split: cluster
  model_id: sentence-transformers/LaBSE
  train_loss: 0.365
  train_factual_f1: 0.455
  train_misinfo_f1: 0.946
  val_loss: 0.433
  val_factual_f1: 0.150
  val_misinfo_f1: 0.925
  test_loss: 0.396
  test_factual_f1: 0.303
  test_misinfo_f1: 0.948

- size: small
  type: claim
  frozen: true
  split: random
  model_id: sentence-transformers/LaBSE
  train_loss: 0.025
  train_factual_f1: 0.896
  val_loss: 0.287
  val_factual_f1: 0.480
  val_misinfo_f1: 0.969
  test_loss: 0.226
  test_factual_f1: 0.071
  test_misinfo_f1: 0.963

- size: medium
  type: claim
  frozen: false
  split: cluster
  model_id: sentence-transformers/LaBSE
  train_loss: 0.183
  train_factual_f1: 0.608
  train_misinfo_f1: 0.965
  val_loss: 0.327
  val_factual_f1: 0.290
  val_misinfo_f1: 0.964
  test_loss: 0.515
  test_factual_f1: 0.195
  test_misinfo_f1: 0.922

- size: large
  type: claim
  frozen: false
  split: cluster
  model_id: sentence-transformers/LaBSE
  train_loss: 0.183
  train_factual_f1: 0.529
  train_misinfo_f1: 0.968
  val_loss: 0.220
  val_factual_f1: 0.299
  val_misinfo_f1: 0.974
  test_loss: 0.317
  test_factual_f1: 0.217
  test_misinfo_f1: 0.041

- size: small
  type: source-tweet
  frozen: false
  split: cluster
  model_id: sentence-transformers/LaBSE
  train_loss: 0.030
  train_factual_f1: 0.984
  train_misinfo_f1: 0.999
  val_loss: 1.281
  val_factual_f1: 0.040
  val_misinfo_f1: 0.927
  test_loss: 1.227
  test_factual_f1: 0.152
  test_misinfo_f1: 0.938

- size: medium
  type: source-tweet
  frozen: false
  split: cluster
  model_id: sentence-transformers/LaBSE
  train_loss: 0.006
  train_factual_f1: 0.996
  train_misinfo_f1: 1.000
  val_loss: 2.146
  val_factual_f1: 0.164
  val_misinfo_f1: 0.959
  test_loss: 3.040
  test_factual_f1: 0.207
  test_misinfo_f1: 0.942

- size: large
  type: source-tweet
  frozen: false
  split: cluster
  model_id: sentence-transformers/LaBSE
  train_loss: 0.825
  train_factual_f1: 0.142
  train_misinfo_f1: 0.975
  val_loss: 0.391
  val_factual_f1: 0.071
  val_misinfo_f1: 0.989
  test_loss: 0.415
  test_factual_f1: 0.078
  test_misinfo_f1: 0.978

- size: small
  type: image
  frozen: false
  split: cluster
  model_id: google/vit-base-patch16-224-in21k
  train_loss: 2.788
  train_factual_f1: 0.332
  train_misinfo_f1: 0.738
  val_loss: 3.905
  val_factual_f1: 0.026
  val_misinfo_f1: 0.686
  test_loss: 3.725
  test_factual_f1: 0.161
  test_misinfo_f1: 0.679

- size: medium
  type: image
  frozen: false
  split: cluster
  model_id: google/vit-base-patch16-224-in21k
  train_loss: 1.500
  train_factual_f1: 0.321
  train_misinfo_f1: 0.808
  val_loss: 2.484
  val_factual_f1: 0.017
  val_misinfo_f1: 0.850
  test_loss: 3.306
  test_factual_f1: 0.087
  test_misinfo_f1: 0.766

- size: large
  type: image
  frozen: false
  split: cluster
  model_id: google/vit-base-patch16-224-in21k
  train_loss: 1.417
  train_factual_f1: 0.225
  train_misinfo_f1: 0.819
  val_loss: 1.494
  val_factual_f1: 0.022
  val_misinfo_f1: 0.840
  test_loss: 2.428
  test_factual_f1: 0.092
  test_misinfo_f1: 0.784

- size: small
  type: graph
  nhops: 1
  hetero_layer_norm: false
  split: random
  model_id: sentence-transformers/LaBSE
  train_loss: 0.013
  train_factual_f1: 0.879
  val_loss: 0.292
  val_factual_f1: 0.143
  val_misinfo_f1: 0.976
  test_loss: 0.660
  test_factual_f1: 0.338
  test_misinfo_f1: 0.937

- size: small
  type: graph
  nhops: 2
  hetero_layer_norm: false
  split: random
  model_id: sentence-transformers/LaBSE
  train_loss: 0.004
  train_factual_f1: 0.915
  val_loss: 0.403
  val_factual_f1: 0.190
  val_misinfo_f1: 0.968
  test_loss: 0.959
  test_factual_f1: 0.403
  test_misinfo_f1: 0.915

- size: small
  type: graph
  nhops: 3
  hetero_layer_norm: false
  split: random
  model_id: sentence-transformers/LaBSE
  train_loss: 0.005
  train_factual_f1: 0.921
  val_loss: 0.429
  val_factual_f1: 0.190
  val_misinfo_f1: 0.971
  test_loss: 1.004
  test_factual_f1: 0.376
  test_misinfo_f1: 0.917

- size: small
  type: graph
  nhops: 3
  hetero_layer_norm: true
  split: random
  model_id: sentence-transformers/LaBSE
  train_loss: 0.007
  train_factual_f1: 0.841
  val_loss: 0.595
  val_factual_f1: 0.310
  val_misinfo_f1: 0.957
  test_loss: 0.308
  test_factual_f1: 0.214
  test_misinfo_f1: 0.979
