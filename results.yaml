- size: small
  type: text
  task: claim
  frozen: false
  split: cluster
  model_id: sentence-transformers/LaBSE
  train_loss: 0.365
  train_factual_f1: 0.455
  train_misinfo_f1: 0.946
  val_loss: 0.433
  val_factual_f1: 0.150
  val_misinfo_f1: 0.925
  test_loss: 0.396
  test_factual_f1: 0.303
  test_misinfo_f1: 0.948

- size: small
  type: text
  task: claim
  frozen: true
  split: cluster
  model_id: sentence-transformers/LaBSE
  train_loss: 0.459
  train_factual_f1: 0.374
  train_misinfo_f1: 0.917
  val_loss: 0.513
  val_factual_f1: 0.157
  val_misinfo_f1: 0.903
  test_loss: 0.511
  test_factual_f1: 0.216
  test_misinfo_f1: 0.934

- size: medium
  type: text
  task: claim
  frozen: false
  split: cluster
  model_id: sentence-transformers/LaBSE
  train_loss: 0.183
  train_factual_f1: 0.608
  train_misinfo_f1: 0.965
  val_loss: 0.327
  val_factual_f1: 0.290
  val_misinfo_f1: 0.964
  test_loss: 0.515
  test_factual_f1: 0.195
  test_misinfo_f1: 0.922

- size: medium
  type: text
  task: claim
  frozen: true
  split: cluster
  model_id: sentence-transformers/LaBSE
  train_loss: 0.425
  train_factual_f1: 0.333
  train_misinfo_f1: 0.942
  val_loss: 0.342
  val_factual_f1: 0.237
  val_misinfo_f1: 0.952
  test_loss: 0.507
  test_factual_f1: 0.173
  test_misinfo_f1: 0.909

- size: large
  type: text
  task: claim
  frozen: false
  split: cluster
  model_id: sentence-transformers/LaBSE
  train_loss: 0.183
  train_factual_f1: 0.529
  train_misinfo_f1: 0.968
  val_loss: 0.220
  val_factual_f1: 0.299
  val_misinfo_f1: 0.974
  test_loss: 0.317
  test_factual_f1: 0.217
  test_misinfo_f1: 0.941

- size: large
  type: text
  task: claim
  frozen: true
  split: cluster
  model_id: sentence-transformers/LaBSE
  train_loss: 0.400
  train_factual_f1: 0.300
  train_misinfo_f1: 0.950
  val_loss: 0.309
  val_factual_f1: 0.262
  val_misinfo_f1: 0.966
  test_loss: 0.378
  test_factual_f1: 0.160
  test_misinfo_f1: 0.940

- size: small
  type: text
  task: tweet
  frozen: false
  split: cluster
  model_id: sentence-transformers/LaBSE
  train_loss: 0.030
  train_factual_f1: 0.984
  train_misinfo_f1: 0.999
  val_loss: 1.281
  val_factual_f1: 0.040
  val_misinfo_f1: 0.927
  test_loss: 1.227
  test_factual_f1: 0.152
  test_misinfo_f1: 0.938

- size: medium
  type: text
  task: tweet
  frozen: false
  split: cluster
  model_id: sentence-transformers/LaBSE
  train_loss: 0.006
  train_factual_f1: 0.996
  train_misinfo_f1: 1.000
  val_loss: 2.146
  val_factual_f1: 0.164
  val_misinfo_f1: 0.959
  test_loss: 3.040
  test_factual_f1: 0.207
  test_misinfo_f1: 0.942

- size: large
  type: text
  task: tweet
  frozen: false
  split: cluster
  model_id: sentence-transformers/LaBSE
  train_loss: 0.825
  train_factual_f1: 0.142
  train_misinfo_f1: 0.975
  val_loss: 0.391
  val_factual_f1: 0.071
  val_misinfo_f1: 0.989
  test_loss: 0.415
  test_factual_f1: 0.078
  test_misinfo_f1: 0.978

- size: small
  type: image
  dropout: 0.2
  frozen: false
  split: cluster
  model_id: google/vit-base-patch16-224-in21k
  train_loss: 0.081
  train_factual_f1: 0.889
  train_misinfo_f1: 0.986
  val_loss: 1.775
  val_factual_f1: 0.059
  val_misinfo_f1: 0.888
  test_loss: 3.097
  test_factual_f1: 0.194
  test_misinfo_f1: 0.870

- size: medium
  type: image
  dropout: 0.2
  frozen: false
  split: cluster
  model_id: google/vit-base-patch16-224-in21k
  train_loss: 0.013
  train_factual_f1: 0.942
  train_misinfo_f1: 0.995
  val_loss: 1.158
  val_factual_f1: 0.047
  val_misinfo_f1: 0.953
  test_loss: 2.669
  test_factual_f1: 0.105
  test_misinfo_f1: 0.935

- size: large
  type: image
  dropout: 0.2
  frozen: false
  split: cluster
  model_id: google/vit-base-patch16-224-in21k
  train_loss:
  train_factual_f1:
  train_misinfo_f1:
  val_loss:
  val_factual_f1:
  val_misinfo_f1:
  test_loss:
  test_factual_f1:
  test_misinfo_f1:

- size: small
  type: graph
  task: claim
  split: cluster
  nhops: 2
  hetero_layer_norm: true
  hidden_dim: 1024
  batch_size: 1024
  input_dropout: 0.2
  dropout: 0.2
  lr: 3e-4
  epochs: 300
  pos_weight: 20
  train_loss: 0.414
  train_factual_f1: 0.563
  val_loss: 2.898
  val_factual_f1: 0.006
  val_misinfo_f1: 0.857
  test_loss: 3.405
  test_factual_f1: 0.267
  test_misinfo_f1: 0.892

- size: medium
  type: graph
  task: claim
  split: cluster
  nhops: 2
  hetero_layer_norm: true
  hidden_dim: 1024
  batch_size: 1024
  input_dropout: 0.2
  dropout: 0.2
  lr: 3e-4
  epochs: 300
  pos_weight: 20
  train_loss: 0.389
  train_factual_f1: 0.529
  val_loss: 1.50
  val_factual_f1: 0.155
  val_misinfo_f1: 0.916
  test_loss: 2.243
  test_factual_f1: 0.250
  test_misinfo_f1: 0.904

- size: large
  type: graph
  task: claim
  split: cluster
  nhops: 2
  hetero_layer_norm: true
  hidden_dim: 1024
  batch_size: 1024
  input_dropout: 0.2
  dropout: 0.2
  lr: 3e-4
  epochs: 300
  pos_weight: 20
  train_loss: 0.232
  train_factual_f1: 0.626
  val_loss: 2.049
  val_factual_f1: 0.285
  val_misinfo_f1: 0.952
  test_loss: 2.003
  test_factual_f1: 0.277
  test_misinfo_f1: 0.919

- size: small
  type: graph
  task: tweet
  split: cluster
  nhops: 2
  hetero_layer_norm: true
  hidden_dim: 1024
  batch_size: 1024
  input_dropout: 0.2
  dropout: 0.2
  lr: 3e-4
  epochs: 300
  pos_weight: 20
  train_loss: 0.168
  train_factual_f1: 0.805
  val_loss: 1.639
  val_factual_f1: 0.038
  val_misinfo_f1: 0.902
  test_loss: 4.786
  test_factual_f1: 0.189
  test_misinfo_f1: 0.932

- size: medium
  type: graph
  task: tweet
  split: cluster
  nhops: 2
  hetero_layer_norm: true
  hidden_dim: 1024
  batch_size: 1024
  input_dropout: 0.2
  dropout: 0.2
  lr: 3e-4
  epochs: 300
  pos_weight: 20
  train_loss: 0.139
  train_factual_f1: 0.809
  val_loss: 2.424
  val_factual_f1: 0.270
  val_misinfo_f1: 0.932
  test_loss: 8.403
  test_factual_f1: 0.173
  test_misinfo_f1: 0.909

- size: large
  type: graph
  task: tweet
  split: cluster
  nhops: 2
  hetero_layer_norm: true
  hidden_dim: 1024
  batch_size: 1024
  input_dropout: 0.2
  dropout: 0.2
  lr: 3e-4
  epochs: 300
  pos_weight: 20
  train_loss: 0.120
  train_factual_f1: 0.814
  val_loss: 2.17
  val_factual_f1: 0.260
  val_misinfo_f1: 0.971
  test_loss: 3.369
  test_factual_f1: 0.269
  test_misinfo_f1: 0.960

- size: small
  type: graph
  task: claim
  split: random
  nhops: 2
  hetero_layer_norm: true
  hidden_dim: 1024
  batch_size: 1024
  input_dropout: 0.2
  dropout: 0.2
  lr: 3e-4
  epochs: 300
  pos_weight: 20
  train_loss: 0.424
  train_factual_f1: 0.565
  val_loss: 3.514
  val_factual_f1: 0.423
  val_misinfo_f1: 0.921
  test_loss: 2.642
  test_factual_f1: 0.083
  test_misinfo_f1: 0.887

- size: medium
  type: graph
  task: claim
  split: random
  nhops: 2
  hetero_layer_norm: true
  hidden_dim: 1024
  batch_size: 1024
  input_dropout: 0.2
  dropout: 0.2
  lr: 3e-4
  epochs: 300
  pos_weight: 20
  train_loss: 0.311
  train_factual_f1: 0.558
  val_loss: 2.277
  val_factual_f1: 0.415
  val_misinfo_f1: 0.938
  test_loss: 2.672
  test_factual_f1: 0.294
  test_misinfo_f1: 0.934

- size: large
  type: graph
  task: claim
  split: random
  nhops: 2
  hetero_layer_norm: true
  hidden_dim: 1024
  batch_size: 1024
  input_dropout: 0.2
  dropout: 0.2
  lr: 3e-4
  epochs: 300
  pos_weight: 20
  train_loss: 0.321
  train_factual_f1: 0.510
  val_loss: 2.400
  val_factual_f1: 0.409
  val_misinfo_f1: 0.938
  test_loss: 1.736
  test_factual_f1: 0.311
  test_misinfo_f1: 0.940

- size: small
  type: graph
  task: tweet
  split: random
  nhops: 2
  hetero_layer_norm: true
  hidden_dim: 1024
  batch_size: 1024
  input_dropout: 0.2
  dropout: 0.2
  lr: 3e-4
  epochs: 300
  pos_weight: 20
  train_loss: 0.106
  train_factual_f1: 0.854
  val_loss: 4.404
  val_factual_f1: 0.585
  val_misinfo_f1: 0.957
  test_loss: 4.584
  test_factual_f1: 0.537
  test_misinfo_f1: 0.961

- size: medium
  type: graph
  task: tweet
  split: random
  nhops: 2
  hetero_layer_norm: true
  hidden_dim: 1024
  batch_size: 1024
  input_dropout: 0.2
  dropout: 0.2
  lr: 3e-4
  epochs: 300
  pos_weight: 20
  train_loss: 0.176
  train_factual_f1: 0.746
  val_loss: 1.717
  val_factual_f1: 0.653
  val_misinfo_f1: 0.955
  test_loss: 1.178
  test_factual_f1: 0.807
  test_misinfo_f1: 0.983

- size: large
  type: graph
  task: tweet
  split: random
  nhops: 2
  hetero_layer_norm: true
  hidden_dim: 1024
  batch_size: 1024
  input_dropout: 0.2
  dropout: 0.2
  lr: 3e-4
  epochs: 300
  pos_weight: 20
  train_loss: 0.116
  train_factual_f1: 0.811
  val_loss: 1.784
  val_factual_f1: 0.634
  val_misinfo_f1: 0.977
  test_loss: 1.995
  test_factual_f1: 0.620
  test_misinfo_f1: 0.976
